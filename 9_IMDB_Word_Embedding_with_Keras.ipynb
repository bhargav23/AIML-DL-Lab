{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhargav23/AIML-DL-Lab/blob/main/9_IMDB_Word_Embedding_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Implement word embedding for IMDB dataset."
      ],
      "metadata": {
        "id": "iDXt0t7Jh6Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uOXRNVtkigDB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load the IMDB dataset ---\n",
        "# The dataset is already preprocessed, and the reviews are converted to sequences of integers.\n",
        "# Each integer represents a specific word in a dictionary.\n",
        "# We'll only consider the top 10,000 most common words in the dataset.\n",
        "vocab_size = 10000\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFC6LJTxihBg",
        "outputId": "d1bf3a4a-1780-478c-c637-b4ae7172519b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Explore the data ---\n",
        "# The 'word_index' is a dictionary mapping words to an integer index.\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved for special characters.\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # Unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# We can create a reverse word index to look up words from their integer representation.\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(text):\n",
        "    \"\"\"\n",
        "    This function takes a sequence of integers and returns the decoded review as a string.\n",
        "    \"\"\"\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "# Let's see an example review\n",
        "print(\"--- Example Decoded Review ---\")\n",
        "print(decode_review(train_data[0]))\n",
        "print(\"Label:\", train_labels[0])\n",
        "print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hgTFSbuimZm",
        "outputId": "ac8e189c-234a-40fe-ceb6-141d3a6e1739"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "--- Example Decoded Review ---\n",
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Label: 1\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Preprocess the data ---\n",
        "# The reviews have different lengths. We need to pad them so they all have the same length.\n",
        "# We'll set a maximum length of 256 words. Reviews longer than this will be truncated,\n",
        "# and shorter reviews will be padded with the <PAD> token.\n",
        "max_length = 256\n",
        "\n",
        "train_data = pad_sequences(train_data, value=word_index[\"<PAD>\"], padding='post', maxlen=max_length)\n",
        "test_data = pad_sequences(test_data, value=word_index[\"<PAD>\"], padding='post', maxlen=max_length)"
      ],
      "metadata": {
        "id": "CcIDAd3AitKO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Build the model ---\n",
        "# The model is a simple sequential model with three layers:\n",
        "# 1. Embedding layer: This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index.\n",
        "#    These vectors are learned as the model trains. The `input_length` argument is deprecated,\n",
        "#    so we build the model with an explicit input shape.\n",
        "# 2. GlobalAveragePooling1D: This layer returns a fixed-length output vector for each example by averaging over the sequence dimension.\n",
        "#    This allows the model to handle input of variable length in a simple way.\n",
        "# 3. Dense layer: This is the output layer with a single neuron and a sigmoid activation function.\n",
        "#    The output is a float between 0 and 1, representing the probability of the review being positive.\n",
        "embedding_dim = 16\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Explicitly build the model to see the summary correctly.\n",
        "# This is necessary because the `input_length` argument in the Embedding layer is deprecated.\n",
        "model.build(input_shape=(None, max_length))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "i2OjvrOUivk2",
        "outputId": "746e1fef-da04-4721-84dc-9cad6ee375d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │       \u001b[38;5;34m160,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,289\u001b[0m (626.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,289</span> (626.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m160,289\u001b[0m (626.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,289</span> (626.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Compile and train the model ---\n",
        "# We'll use the 'adam' optimizer and 'binary_crossentropy' as the loss function,\n",
        "# which is suitable for a binary classification problem.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# We'll train the model for 30 epochs with a batch size of 512.\n",
        "# We'll also use a validation set to monitor the model's performance on unseen data during training.\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=30,\n",
        "    batch_size=512,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j2X0bF4iyiA",
        "outputId": "d3db6682-77da-45be-9c2d-562254880b62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5363 - loss: 0.6920 - val_accuracy: 0.6894 - val_loss: 0.6844\n",
            "Epoch 2/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6935 - loss: 0.6800 - val_accuracy: 0.7140 - val_loss: 0.6583\n",
            "Epoch 3/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7010 - loss: 0.6493 - val_accuracy: 0.7594 - val_loss: 0.6092\n",
            "Epoch 4/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7636 - loss: 0.5968 - val_accuracy: 0.7822 - val_loss: 0.5464\n",
            "Epoch 5/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8092 - loss: 0.5262 - val_accuracy: 0.8166 - val_loss: 0.4821\n",
            "Epoch 6/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8346 - loss: 0.4593 - val_accuracy: 0.8378 - val_loss: 0.4301\n",
            "Epoch 7/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8536 - loss: 0.4071 - val_accuracy: 0.8382 - val_loss: 0.3978\n",
            "Epoch 8/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8517 - loss: 0.3749 - val_accuracy: 0.8562 - val_loss: 0.3669\n",
            "Epoch 9/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8760 - loss: 0.3371 - val_accuracy: 0.8580 - val_loss: 0.3489\n",
            "Epoch 10/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8849 - loss: 0.3106 - val_accuracy: 0.8680 - val_loss: 0.3331\n",
            "Epoch 11/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8878 - loss: 0.2959 - val_accuracy: 0.8690 - val_loss: 0.3213\n",
            "Epoch 12/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8960 - loss: 0.2820 - val_accuracy: 0.8740 - val_loss: 0.3124\n",
            "Epoch 13/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8988 - loss: 0.2692 - val_accuracy: 0.8750 - val_loss: 0.3096\n",
            "Epoch 14/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9042 - loss: 0.2561 - val_accuracy: 0.8754 - val_loss: 0.3005\n",
            "Epoch 15/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9042 - loss: 0.2522 - val_accuracy: 0.8800 - val_loss: 0.2943\n",
            "Epoch 16/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9102 - loss: 0.2391 - val_accuracy: 0.8790 - val_loss: 0.2926\n",
            "Epoch 17/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9172 - loss: 0.2262 - val_accuracy: 0.8828 - val_loss: 0.2881\n",
            "Epoch 18/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9218 - loss: 0.2167 - val_accuracy: 0.8752 - val_loss: 0.2953\n",
            "Epoch 19/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 0.9200 - loss: 0.2157 - val_accuracy: 0.8816 - val_loss: 0.2850\n",
            "Epoch 20/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9243 - loss: 0.2051 - val_accuracy: 0.8860 - val_loss: 0.2810\n",
            "Epoch 21/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9280 - loss: 0.1979 - val_accuracy: 0.8794 - val_loss: 0.2883\n",
            "Epoch 22/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9305 - loss: 0.1923 - val_accuracy: 0.8894 - val_loss: 0.2788\n",
            "Epoch 23/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9333 - loss: 0.1855 - val_accuracy: 0.8766 - val_loss: 0.2934\n",
            "Epoch 24/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9352 - loss: 0.1793 - val_accuracy: 0.8816 - val_loss: 0.2839\n",
            "Epoch 25/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9371 - loss: 0.1757 - val_accuracy: 0.8882 - val_loss: 0.2778\n",
            "Epoch 26/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9387 - loss: 0.1710 - val_accuracy: 0.8848 - val_loss: 0.2866\n",
            "Epoch 27/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9337 - loss: 0.1783 - val_accuracy: 0.8856 - val_loss: 0.2790\n",
            "Epoch 28/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9424 - loss: 0.1606 - val_accuracy: 0.8884 - val_loss: 0.2788\n",
            "Epoch 29/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9450 - loss: 0.1543 - val_accuracy: 0.8902 - val_loss: 0.2789\n",
            "Epoch 30/30\n",
            "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9492 - loss: 0.1483 - val_accuracy: 0.8842 - val_loss: 0.2887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Evaluate the model ---\n",
        "# Finally, we'll evaluate the model's performance on the test set.\n",
        "results = model.evaluate(test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Test Loss: {results[0]}\")\n",
        "print(f\"Test Accuracy: {results[1]}\")\n",
        "print(\"-\" * 30)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 - 1s - 2ms/step - accuracy: 0.8737 - loss: 0.3058\n",
            "\n",
            "--- Model Evaluation ---\n",
            "Test Loss: 0.30575504899024963\n",
            "Test Accuracy: 0.8737199902534485\n",
            "------------------------------\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91qZKyFWh3d1",
        "outputId": "46e9e35a-2c9c-4bf7-e7fd-6fea15d7132f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Make predictions on new data ---\n",
        "# You can use the trained model to make predictions on new reviews.\n",
        "# Here's an example of how you would preprocess a new review and make a prediction.\n",
        "def preprocess_text(text):\n",
        "    words = text.lower().split()\n",
        "    encoded_review = [word_index.get(word, 2) for word in words] # 2 is for <UNK>\n",
        "    padded_review = pad_sequences([encoded_review], value=word_index[\"<PAD>\"], padding='post', maxlen=max_length)\n",
        "    return padded_review\n",
        "\n",
        "# Example of a positive review\n",
        "positive_review = \"this movie was fantastic I really enjoyed it and would recommend it to everyone\"\n",
        "preprocessed_positive = preprocess_text(positive_review)\n",
        "prediction_positive = model.predict(preprocessed_positive)\n",
        "print(f\"Prediction for positive review: {prediction_positive[0][0]}\")\n",
        "\n",
        "# Example of a negative review\n",
        "negative_review = \"it was a terrible movie I would not recommend it to anyone\"\n",
        "preprocessed_negative = preprocess_text(negative_review)\n",
        "prediction_negative = model.predict(preprocessed_negative)\n",
        "print(f\"Prediction for negative review: {prediction_negative[0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1KJRHi-iaBP",
        "outputId": "2499291f-f01b-4176-a1f3-59b8cf4fea60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "Prediction for positive review: 0.6568941473960876\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Prediction for negative review: 0.12901991605758667\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}